{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attentioned_LSTM HW3-ver1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingyungkim/SarcasmDetection/blob/master/Attentioned_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcAvpMNhZ6c6",
        "colab_type": "text"
      },
      "source": [
        "# Clone Git\n",
        "\n",
        "Run the following to get the required files needed for this assignment. \n",
        "\n",
        "TODO: switch repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-rDRgbYlvfI",
        "colab_type": "code",
        "outputId": "8a407da1-f447-44bc-c6f2-fcea28ed859d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/cis700/hw3-solutions.git\n",
        "!mv hw3-solutions/* .\n",
        "!rm -rf hw3-solutions/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hw3-solutions'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 17 (delta 2), reused 14 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "mv: cannot move 'hw3-solutions/data' to './data': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCEowgppabSx",
        "colab_type": "text"
      },
      "source": [
        "# Part 1.  Setting up the Reddit dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKY6gdpKbT_M",
        "colab_type": "text"
      },
      "source": [
        "For this assignment, we are going to use the Reddit sarcasm dataset.  Since sarcasm is difficult to express via text, Redditors frequently end sarcastic comments with \"/s\".  The Reddit dataset uses the presence of this \"/s\" token to create a labeled dataset of sarcastic and non-sarcastic comments.  The original Reddit dataset can be found here: https://www.kaggle.com/danofer/sarcasm\n",
        "\n",
        "We've made some slight modifications to the dataset -- we've removed metadata and balanced the dataset (only 1% of Reddit comments are actually sarcastic, but 50% of the training and test examples are sarcastic in the modified dataset).\n",
        "\n",
        "Note that even within the niche of sarcasm-based NLP, there are better, cleaner, and larger datasets than this Reddit dataset.  I've selected this one specifically because there are many teachable characteristics of the dataset.\n",
        "\n",
        "Run the following commands to unzip the csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_1HNNeZaiIj",
        "colab_type": "code",
        "outputId": "05f090d8-dd6a-4df0-b84a-aaec779f3246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!gzip -d ./data/reddit_train.csv.gz\n",
        "!gzip -d ./data/reddit_test.csv.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: ./data/reddit_train.csv.gz: No such file or directory\n",
            "gzip: ./data/reddit_test.csv.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mQQ_Ux2bf4y",
        "colab_type": "text"
      },
      "source": [
        "The following cells have all of the necessary imports for this homework.  We see 2 new packages.\n",
        "\n",
        "\n",
        "1.   **torchtext**.  Recall that torchvision built many image datasets, CV models, and image processing utilities into the PyTorch framework.  The torchtext package does the same for NLP -- it has many utilities for handling tokenization, variable-length sequences, feature vectorization.\n",
        "2.   **spaCy**.  This is a state-of-the-art English language tokenizer.  We will pass this as an input to the torchtext equivalent of a DataLoader.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M13DP7Jvbeuz",
        "colab_type": "code",
        "outputId": "bcca3118-5b23-4d85-d2d2-b7bcc8f7f589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "# !pip install bert-pytorch #ADDED BY MK\n",
        "# !pip install pytorch-pretrained-bert #ADDED BY MK"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovS_g7dvccrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data as data\n",
        "from torchtext.vocab import Vectors\n",
        "import spacy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import time  # TODO: remove\n",
        "from google.colab import drive\n",
        "from helper import Logger\n",
        "import gc\n",
        "# from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM #ADDED BY MK\n",
        "# from pytorch_pretrained_bert import BertConfig, BertForTokenClassification, BertAdam #ADDED BY MK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3JasABrurXn",
        "colab_type": "code",
        "outputId": "a6645635-e3fd-4527-97cf-9a5b72a55df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# reset all environment conditions\n",
        "\n",
        "def reset_env():\n",
        "    SEED = 1234\n",
        "    random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUdd2ECdCjS",
        "colab_type": "text"
      },
      "source": [
        "## Q1.1 Review of the dataset\n",
        "\n",
        "Let's first understand the structure of the dataset.\n",
        "\n",
        "*   Print out the headers and the first five rows of reddit_train.csv.  Put this in your writeup.\n",
        "*   As a review of part 1, describe each input and state whether it is fixed-length or variable-length in your writeup.\n",
        "*   Print out size of both datasets and put the lengths in your writeup.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T23DwRC5dZIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reddit_train_df = pd.read_csv('./data/reddit_train.csv')\n",
        "# reddit_test_df = pd.read_csv('./data/reddit_test.csv')\n",
        "# print(reddit_train_df.head())\n",
        "\n",
        "# print(len(reddit_train_df.index))\n",
        "# print(len(reddit_test_df.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcmwXGEfPQNW",
        "colab_type": "text"
      },
      "source": [
        "## Q1.2 Featurizing the dataset with torchtext\n",
        "\n",
        "Computer vision has torchvision; NLP has torchtext.  In this problem, we will create and featurize a torchtext dataset with Fields, a data structure that can automatically featurize text with embeddings.\n",
        "\n",
        "First, create a tokenizer using spacy_en.  Create two torchtext data fields using data.Field from torchtext.data:\n",
        "\n",
        "*   a sequential field named TEXT for comment and parent_comment.  (*Hint: since this is natural language, this is sequential data.  Use your tokenizer and convert all characters to lowercase.*)\n",
        "*   a non-sequential field named LABEL for the labels.  (*Hint: since this is a categorical variable, it is not sequential.  Furthermore, it does not require a vocabulary since there are no words to embed.*)\n",
        "\n",
        "Next, look at the documentation for data.TabularDataset.splits and create `train_ds` and `test_ds`.  You will need the paths to the training and test datasets, the format, and the mapping from columns to fields.  Note that the first column in the csv's should not be a field.  This step creates 3 torchtext objects for each row in the dataset, so it will take some time (between 2-10 minutes).\n",
        "\n",
        "We then build our vocabulary with GloVE, a word embedding similar to Word2Vec.  Create a vocabulary from TEXT using the train dataset (*Hint: look at the documentation for Field.build_vocab*).  Use the glove.6B.100d word embedding, and save the vocbulary.  The first time you run this, it will take roughly 5-10 minutes to download.  The pretrained model will then be stored in the ./.vector_cache folder, and rerunning this command will take negligible time.  Store the final vocabulary in the `vocab` variable.\n",
        "\n",
        "Finally, print out a single example from `train_ds` and print out the properties of `vocab` ('freqs', 'itos', 'stoi', 'vectors').  Include this printouts in the writeup.  Explain what the properties of `vocab` are.  These are the only things you need to include in your writeup for Q1.1b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBPNdzZJhZmY",
        "colab_type": "code",
        "outputId": "ba7f4026-1b1e-4e8b-9f85-2fc0313891c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy_en = spacy.load('en')\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "def tokenizer(text):  # create a tokenizer function\n",
        "   return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased').tokenize         #ADDED BY MK\n",
        "  \n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
        "LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "train_ds, test_ds = data.TabularDataset.splits(\n",
        "    path='./data/', train='reddit_train.csv',\n",
        "    test='reddit_test.csv', format='csv', skip_header=True,\n",
        "    fields=[('index', None), ('label', LABEL), ('comment', TEXT), ('parent_comment', TEXT)])\n",
        "\n",
        "TEXT.build_vocab(train_ds,vectors=\"glove.6B.100d\")\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "print(vocab.__dict__.keys())\n",
        "# vocab.freqs\n",
        "# vocab.itos\n",
        "# vocab.stoi\n",
        "# vocab.vectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zejlNkZbPl9m",
        "colab_type": "text"
      },
      "source": [
        "## Utility cells for modeling\n",
        "\n",
        "We've set up a few utility cells here.  Use these as you see fit.\n",
        "\n",
        "1.   Cell to set up a logger and Tensorboard.\n",
        "2.   Cell to keep track of hyperparameters.\n",
        "3.   Cell with functions for training and testing loops.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALbxEo4-Pk89",
        "colab_type": "code",
        "outputId": "744dc984-0b74-4cb3-8f46-914d2ead0c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "### Tensorboard setup\n",
        "# asdf\n",
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "\n",
        "# !./ngrok authtoken 7rHP2EU3WwBpFXGh7cH3z_6VS67KiDzaRyVAKTLt8St\n",
        "    \n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\"\n",
        "\n",
        "logger = Logger('./logs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ngrok already installed\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X8W3AdB5vhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### hyperparameters\n",
        "# overall\n",
        "all_models_hyperparameters = {'embedding_dim': 100,                             \n",
        "                              'output_dim': 1,\n",
        "                              'vocabulary_size': len(TEXT.vocab),\n",
        "                              'train_batch_size': 40,\n",
        "                              'test_batch_size': 40}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxi8SQszDeQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_example(m, ex, variable_length):\n",
        "    lab, child, parent = ex.label.to(device), ex.comment.to(device), ex.parent_comment.to(device)\n",
        "    if variable_length:\n",
        "        lengths = [list(c.size())[0] for c in child.permute(1, 0)]\n",
        "        out = torch.squeeze(m(child, parent, torch.LongTensor(lengths).cpu()), 1)\n",
        "    else:\n",
        "        out = torch.squeeze(m(child, parent), 1)\n",
        "    return lab, out\n",
        "\n",
        "\n",
        "def train_model(model_name, model, optimizer, loss_criterion, num_epochs, variable_length=False, parents=True):\n",
        "    tick = time.time()\n",
        "    # make sure model and loss are on CUDA\n",
        "    model = model.to(device)\n",
        "    loss_criterion = loss_criterion.to(device)\n",
        "\n",
        "    logger = Logger('./logs/' + model_name + str(time.time()))\n",
        "    batch_num = 0\n",
        "    max_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"starting epoch \", epoch, \", \", time.time() - tick)\n",
        "        for example in train_iter:\n",
        "            batch_num += 1\n",
        "            label, output = process_example(model, example, variable_length)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_criterion(output.float(), label.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            ## Tensorboard stuff\n",
        "            \n",
        "            # computing train accuracy\n",
        "            predicted = torch.round(output.data)\n",
        "            total = label.size(0)\n",
        "            correct = (predicted.float() == label.to(device).float()).sum().item()\n",
        "            accuracy = correct / total\n",
        "            info = { 'loss': loss, 'accuracy': accuracy }\n",
        "            \n",
        "            # computing test accuracy\n",
        "            if batch_num % 20000 == 0:\n",
        "                test_total = 0\n",
        "                test_correct = 0\n",
        "                with torch.no_grad():\n",
        "                    for test_example in test_iter:\n",
        "                        test_label, test_output = process_example(model, test_example, variable_length)\n",
        "                        test_predicted = torch.round(test_output.data)\n",
        "                        test_total += test_label.size(0)\n",
        "                        test_correct += (test_predicted.float() == test_label.to(device).float()).sum().item()\n",
        "                        break;  # only takes one test batch\n",
        "                test_accuracy = test_correct / test_total\n",
        "                info['test_accuracy'] = test_accuracy                  \n",
        "                if test_accuracy > max_accuracy:\n",
        "                    torch.save(model.state_dict(), \"/content/gdrive/My Drive/hw-3-models/\" + model_name + \"-\" + str(batch_num))\n",
        "\n",
        "            for tag, value in info.items():\n",
        "                logger.scalar_summary(tag, value, batch_num + 1)        \n",
        "    return model\n",
        "\n",
        "# def test_model_accuracy(model, variable_length=False):\n",
        "#     model = model.to(device)\n",
        "#     confusion_mtx = np.zeros((2, 2))\n",
        "#     test_total = 0\n",
        "#     test_correct = 0\n",
        "#     with torch.no_grad():\n",
        "#         for test_example in test_iter:\n",
        "#             test_label, test_output = process_example(model, test_example, variable_length)\n",
        "#             test_predicted = torch.round(test_output.data)\n",
        "#             test_total += test_label.size(0)\n",
        "#             test_correct += (test_predicted.float() == test_label.to(device).float()).sum().item()\n",
        "# #             print(test_correct / test_total)\n",
        "#     test_accuracy = test_correct / test_total\n",
        "#     return test_accuracy\n",
        "\n",
        "def test_model_confusion_matrix(model, variable_length=False):\n",
        "    model = model.to(device)\n",
        "    confusion_mtx = np.zeros((2, 2))\n",
        "    with torch.no_grad():\n",
        "        for test_example in test_iter:\n",
        "            test_label = test_example.label.to(device)\n",
        "            test_child = test_example.comment.to(device)\n",
        "            test_parent = test_example.parent_comment.to(device)\n",
        "            \n",
        "            if test_child.size()[0] > 4:  # ensures we're looking at sufficiently large comments\n",
        "                if variable_length:\n",
        "                    lengths = [list(c.size())[0] for c in test_child.permute(1, 0)]\n",
        "#                     output = torch.squeeze(model(comment, torch.LongTensor(lengths).cpu()), 1)\n",
        "                    test_output = torch.squeeze(model(test_child, test_parent, torch.LongTensor(lengths).to(device)), 1)\n",
        "\n",
        "                else:\n",
        "                    test_output = torch.squeeze(model(test_child, test_parent), 1)\n",
        "                test_predicted = torch.round(test_output.data)\n",
        "                current_cm = confusion_matrix(test_label.cpu().numpy(), test_predicted.cpu().numpy())\n",
        "                confusion_mtx += current_cm\n",
        "    tn, fp, fn, tp = confusion_mtx.ravel()\n",
        "    accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
        "    recall = tp / (tp + fn)\n",
        "    precision = tp / (tp + fp)\n",
        "    print(\"Accuracy: \", accuracy)\n",
        "    print(\"TPR / Recall / Sensitivity: \", recall)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"F1: \", 2 * (precision * recall) / (precision + recall))\n",
        "    return tn, fp, fn, tp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2-_bPaflAw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, test_iter = data.Iterator.splits(\n",
        "    (train_ds, test_ds), sort_key=lambda x: len(x.comment), shuffle=True,\n",
        "    batch_sizes=(all_models_hyperparameters['train_batch_size'], all_models_hyperparameters['test_batch_size']), device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA5I1F-XSdKK",
        "colab_type": "text"
      },
      "source": [
        "# Part 2.  Modeling sarcasm without context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXVln6-xQm9-",
        "colab_type": "text"
      },
      "source": [
        "##Question 2.1 Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzdgm3gQmQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raise NotimplementedError\n",
        "# class LogisticRegression(nn.Module):\n",
        "#     def __init__(self, embedding_dim, output_dim):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)                     # we used GLove 100-dim   => (MK) Bert 768-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "#         self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "#     def forward(self, text, parent=None):\n",
        "#         text = text.permute(1, 0)\n",
        "#         embedded = self.embed(text)\n",
        "#         embedded = embedded.permute(0, 2, 1)\n",
        "#         avg_embedded = torch.mean(embedded, dim=2)\n",
        "#         return torch.sigmoid(self.fc(avg_embedded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29xcYWYZLRZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset_env()\n",
        "# # base lr\n",
        "# # attempt 0: 0.001 // peaks at 7 epochs\n",
        "# base_lr_hyperparameters = {'learning_rate': 0.01,\n",
        "#                            'num_epochs': 10} # 80k examples}\n",
        "\n",
        "# logistic_reg = LogisticRegression(all_models_hyperparameters['embedding_dim'], \n",
        "#                                   all_models_hyperparameters['output_dim'])\n",
        "# optimizer = optim.Adam(logistic_reg.parameters(), lr=base_lr_hyperparameters['learning_rate'])\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# logistic_reg = train_model('Logistic-Regression-attempt-0-', logistic_reg, optimizer, criterion, base_lr_hyperparameters['num_epochs'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw58jcanEzGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # logistic_reg = LogisticRegression(all_models_hyperparameters['embedding_dim'], \n",
        "# #                                   all_models_hyperparameters['output_dim'])\n",
        "# # logistic_reg.load_state_dict(torch.load(\"/content/gdrive/My Drive/hw-3-models/Logistic-Regression-attempt-0--100000\"))\n",
        "\n",
        "# test_model_accuracy(logistic_reg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IvJ-fpLlgIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_model_confusion_matrix(logistic_reg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZBDpnhZQtwh",
        "colab_type": "text"
      },
      "source": [
        "##Question 2.2 CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap1LzDCuh_I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class CNN1d(nn.Module):\n",
        "#     def __init__(self, embedding_dim, num_features, filter_sizes, output_dim, dropout):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)  # we used GLove 100-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "\n",
        "#         self.convs = nn.ModuleList([\n",
        "#             nn.Conv1d(in_channels=embedding_dim,\n",
        "#                       out_channels=num_features,\n",
        "#                       kernel_size=fs)\n",
        "#             for fs in filter_sizes\n",
        "#         ])\n",
        "\n",
        "#         self.fc = nn.Linear(len(filter_sizes) * num_features, output_dim)\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     def forward(self, text, parent=None):\n",
        "#         text = text.permute(1, 0)\n",
        "#         embedded = self.embed(text)\n",
        "#         embedded = embedded.permute(0, 2, 1)\n",
        "#         conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "#         pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "#         cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "#         return torch.sigmoid(self.fc(cat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htix_t7GsV5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # base CNN\n",
        "# # attempt 0: 60 x [3,4,5] x 0.001, dropout=0.5 (good) 0.7981794259015601\n",
        "# # attempt 1: 80 x [3,4,5] x 0.0005, dropout=0.2 (bad)\n",
        "# # attempt 2: 60 x [3,4,5] x 0.001, dropout=0.2 (bad)\n",
        "# # attempt 3: 80 x [2,3,4,5,6] x  0.0005 x dropout=0.5 (bad)\n",
        "# # attempt 4: 80 x [1,2,3,4,5] x 0.0005 x 0.5 (good) 0.8047 train; 0.7211 test\n",
        "# # attempt 5: 80 x [1,2,3,4,5] x 0.0001 x 0.5 dropout x 30 epochs (good) 0.83 train; 0.7022 test\n",
        "# # attempt 6: 40 x [1,2,3,4,5] x 0.0001 x 0.6 dropout x 15 epochs (good) 0.79 train; 0.707 test\n",
        "# # attempt 7: 200 x [1, 3, 5] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 8: 80 x [1, 1, 2, 2, 3, 3, 4, 5, 8, 10] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 9: 200 x [1, 2, 3, 4, 5, 8, 10] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 10: 200 x [1, 2, 3] x 0.0001 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 11: 80 x [1, 2, 3] x 0.0001 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 12: 20 x [3,4,5] x 0.001 x 0.5 dropout x 10 epochs\n",
        "# # attempt 13: 40 x [3,4,5] x 0.001 x 0.5 dropout x 20 epochs\n",
        "# # attempt 14: 20 x [3,4,5] x 0.001 x 0.5 dropout x 20 epochs\n",
        "# # attempt 14: 20 x [3,4,5] x 0.001 x 0.5 dropout x 25 epochs x bs 40\n",
        "# base_cnn_hyperparameters = {'num_features': 20,\n",
        "#                             'filter_sizes': [3, 4, 5], #[2-6] didn't work\n",
        "#                             'learning_rate': 0.001,\n",
        "#                             'num_epochs': 25,\n",
        "#                             'dropout': 0.2}\n",
        "# cnn = CNN1d(all_models_hyperparameters['embedding_dim'],\n",
        "#             base_cnn_hyperparameters['num_features'],\n",
        "#             base_cnn_hyperparameters['filter_sizes'],\n",
        "#             all_models_hyperparameters['output_dim'],\n",
        "#             base_cnn_hyperparameters['dropout']).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(cnn.parameters(), lr=base_cnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# cnn = train_model('CNN-attempt-14-', cnn, optimizer, criterion, base_cnn_hyperparameters['num_epochs'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9dXDDHmqg44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # cnn = CNN1d(all_models_hyperparameters['embedding_dim'],\n",
        "# #             base_cnn_hyperparameters['num_features'],\n",
        "# #             base_cnn_hyperparameters['filter_sizes'],\n",
        "# #             all_models_hyperparameters['output_dim'],\n",
        "# #             all_models_hyperparameters['dropout']).to(device)\n",
        "# # cnn.load_state_dict(torch.load(\"/content/gdrive/My Drive/hw-3-models/CNN-attempt-12--240000\"))\n",
        "\n",
        "# test_model_confusion_matrix(cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4FUVYqWRQp3",
        "colab_type": "text"
      },
      "source": [
        "##Question 2.3 LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDGeFhBx28VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class RNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "#                  bidirectional, dropout, pad_idx):\n",
        "        \n",
        "#         super().__init__()        \n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "#         self.rnn = nn.LSTM(embedding_dim, \n",
        "#                            hidden_dim, \n",
        "#                            num_layers=n_layers, \n",
        "#                            bidirectional=bidirectional, \n",
        "#                            dropout=dropout)\n",
        "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "#     def forward(self, text, parent, text_lengths):\n",
        "        \n",
        "#         embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "#         #pack sequence\n",
        "#         packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "#         packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "#         #unpack sequence\n",
        "#         output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "#         hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "#         #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "#         return torch.sigmoid(self.fc(hidden.squeeze(0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cfX06Lxh_Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # base RNN\n",
        "# # attempt 0: 15 epochs, 256 hiddens, 2 layers, dropout = 0.2, lr = 0.0005\n",
        "# # attempt 1: 15 epochs, 128 hiddens, 1 layers, dropout = 0.5, lr = 0.0001 (not quite as good)\n",
        "# # attempt 2: 15 epochs, 256 hiddens, 1 layers, dropout = 0.2, lr = 0.001\n",
        "# # attempt 3: 10 epochs, 50 hiddens, 1 layers, dropout = 0.5, lr = 0.001\n",
        "# # attempt 4: 20 epochs, 100 hiddens, 1 layers, dropout = 0.5, lr = 0.001\n",
        "# base_rnn_hyperparameters = {'hidden_size': 100,\n",
        "#                             'number_of_layers': 1,\n",
        "#                             'bidirectional': True,\n",
        "#                             'dropout': 0.2,\n",
        "#                             'pad_idx': TEXT.vocab.stoi[TEXT.pad_token],\n",
        "#                             'learning_rate': 0.001,\n",
        "#                             'num_epochs': 20}\n",
        "# rnn = RNN(all_models_hyperparameters['vocabulary_size'],\n",
        "#           all_models_hyperparameters['embedding_dim'], \n",
        "#           base_rnn_hyperparameters['hidden_size'],\n",
        "#           all_models_hyperparameters['output_dim'],\n",
        "#           base_rnn_hyperparameters['number_of_layers'],\n",
        "#           base_rnn_hyperparameters['bidirectional'],\n",
        "#           all_models_hyperparameters['dropout'],\n",
        "#           base_rnn_hyperparameters['pad_idx'])\n",
        "\n",
        "# optimizer = optim.Adam(rnn.parameters(), lr=base_rnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# rnn = train_model('RNN-attempt-0-', rnn, optimizer, criterion, base_rnn_hyperparameters['num_epochs'], variable_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_TFcvkGh_TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_model_confusion_matrix(rnn, variable_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FqT-CX5arho",
        "colab_type": "text"
      },
      "source": [
        "# Part 3.  Modeling sarcasm by concatenating context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLndccIPWTq",
        "colab_type": "text"
      },
      "source": [
        "## Utility cells for modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-elF8iXPQew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ### hyperparameters\n",
        "# # overall\n",
        "# all_models_hyperparameters = {'embedding_dim': 100,\n",
        "#                               'output_dim': 1,\n",
        "#                               'dropout': 0.5,\n",
        "#                               'vocabulary_size': len(TEXT.vocab),\n",
        "#                               'number_of_epochs': 10,\n",
        "#                               'batch_size': 50}\n",
        "\n",
        "# # base lr\n",
        "# # attempt 0: 0.001\n",
        "# two_utt_lr_hyperparameters = {'learning_rate': 0.001}\n",
        "\n",
        "# # base CNN\n",
        "# # attempt 0: 60 x [3,4,5] x 0.001, dropout=0.5 (good) 0.7981794259015601\n",
        "# # attempt 1: 80 x [3,4,5] x 0.0005, dropout=0.2 (bad)\n",
        "# # attempt 2: 60 x [3,4,5] x 0.001, dropout=0.2 (bad)\n",
        "# # attempt 3: 80 x [2,3,4,5,6] x  0.0005 x dropout=0.5 (bad)\n",
        "# # attempt 4: 80 x [1,2,3,4,5] x 0.0005 x 0.5 (good) 0.8047 train; 0.7211 test\n",
        "# # attempt 5: 80 x [1,2,3,4,5] x 0.0001 x 0.5 dropout x 30 epochs (good) 0.83 train; 0.7022 test\n",
        "# # attempt 6: 40 x [1,2,3,4,5] x 0.0001 x 0.6 dropout x 15 epochs (good) 0.79 train; 0.707 test\n",
        "# # attempt 7: 200 x [1, 3, 5] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 8: 80 x [1, 1, 2, 2, 3, 3, 4, 5, 8, 10] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 9: 200 x [1, 2, 3, 4, 5, 8, 10] x 0.0005 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 10: 200 x [1, 2, 3] x 0.0001 x 0.5 dropout x 15 epochs (bad)\n",
        "# # attempt 11: 80 x [1, 2, 3] x 0.0001 x 0.5 dropout x 15 epochs (bad)\n",
        "# two_utt_cnn_hyperparameters = {'num_features': 200,\n",
        "#                             'filter_sizes': [1, 2, 3], #[2-6] didn't work\n",
        "#                             'learning_rate': 0.0002}\n",
        "\n",
        "# # base RNN\n",
        "# # attempt 0: 15 epochs, 256 hiddens, 2 layers, dropout = 0.2, lr = 0.0005\n",
        "# # attempt 1: 15 epochs, 128 hiddens, 1 layers, dropout = 0.5, lr = 0.0001 (not quite as good)\n",
        "# # # attempt 2: 15 epochs, 256 hiddens, 1 layers, dropout = 0.2, lr = 0.001\n",
        "# two_utt_rnn_hyperparameters = {'hidden_size': 256,\n",
        "#                             'number_of_layers': 1,\n",
        "#                             'bidirectional': True,\n",
        "#                             'dropout': 0.2,\n",
        "#                             'pad_idx': TEXT.vocab.stoi[TEXT.pad_token],\n",
        "#                             'learning_rate': 0.0001}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvRNbKln3f7-",
        "colab_type": "text"
      },
      "source": [
        "##Question 3.1 Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK2NokW_wkxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class ConcatenatedLogisticRegression(nn.Module):\n",
        "#     def __init__(self, embedding_dim, output_dim):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)  # we used GLove 100-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "#         self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "#     def forward(self, text, parent=None):\n",
        "#         text = torch.cat((parent, text))\n",
        "#         text = text.permute(1, 0)\n",
        "#         embedded = self.embed(text)\n",
        "#         embedded = embedded.permute(0, 2, 1)\n",
        "#         avg_embedded = torch.mean(embedded, dim=2)\n",
        "#         return torch.sigmoid(self.fc(avg_embedded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1dpXZn7bv3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tick = time.time()\n",
        "# logistic_reg = ConcatenatedLogisticRegression(all_models_hyperparameters['embedding_dim'], \n",
        "#                                   all_models_hyperparameters['output_dim'])\n",
        "\n",
        "# optimizer = optim.Adam(logistic_reg.parameters(), lr=two_utt_lr_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# logistic_reg = train_model('cu-Logistic-Regression-attempt-0-', logistic_reg, optimizer, criterion)\n",
        "# print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ38S7AqbvzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logistic_reg = ConcatenatedLogisticRegression(all_models_hyperparameters['embedding_dim'], \n",
        "#                                   all_models_hyperparameters['output_dim'])\n",
        "# logistic_reg.load_state_dict(torch.load(\"/content/gdrive/My Drive/cu-Logistic-Regression-attempt-0-\"))\n",
        "# # print(\"done!\")\n",
        "\n",
        "# test_model_confusion_matrix(logistic_reg, variable_length=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOlKlcnQ-HXb",
        "colab_type": "text"
      },
      "source": [
        "##Question 3.2 CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qce-Anie-Pld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class ConcatenatedCNN1d(nn.Module):\n",
        "#     def __init__(self, embedding_dim, num_features, filter_sizes, output_dim, dropout):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)  # we used GLove 100-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "\n",
        "#         self.convs = nn.ModuleList([\n",
        "#             nn.Conv1d(in_channels=embedding_dim,\n",
        "#                       out_channels=num_features,\n",
        "#                       kernel_size=fs)\n",
        "#             for fs in filter_sizes\n",
        "#         ])\n",
        "\n",
        "#         self.fc = nn.Linear(len(filter_sizes) * num_features, output_dim)\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     def forward(self, text, parent=None):\n",
        "#         text = text.permute(1, 0)\n",
        "#         parent = parent.permute(1, 0)\n",
        "#         text = torch.cat((parent, text), dim=1)\n",
        "#         embedded = self.embed(text)\n",
        "#         embedded = embedded.permute(0, 2, 1)\n",
        "#         conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "#         pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "#         cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "#         return torch.sigmoid(self.fc(cat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-mfEvUjoAvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tick = time.time()\n",
        "# concat_cnn = ConcatenatedCNN1d(all_models_hyperparameters['embedding_dim'],\n",
        "#             two_utt_cnn_hyperparameters['num_features'],\n",
        "#             two_utt_cnn_hyperparameters['filter_sizes'],\n",
        "#             all_models_hyperparameters['output_dim'],\n",
        "#             all_models_hyperparameters['dropout']).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(concat_cnn.parameters(), lr=two_utt_cnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# concat_cnn = train_model('concat-CNN-attempt-0-', concat_cnn, optimizer, criterion)\n",
        "# print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHlzw46OoAtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concat_cnn = ConcatenatedCNN1d(all_models_hyperparameters['embedding_dim'],\n",
        "#             base_cnn_hyperparameters['num_features'],\n",
        "#             base_cnn_hyperparameters['filter_sizes'],\n",
        "#             all_models_hyperparameters['output_dim'],\n",
        "#             all_models_hyperparameters['dropout']).to(device)\n",
        "# concat_cnn.load_state_dict(torch.load(\"/content/gdrive/My Drive/concat-CNN-attempt-0-\"))\n",
        "# # # print(\"done!\")\n",
        "\n",
        "# test_model_confusion_matrix(concat_cnn, variable_length=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9meBKReFDh8",
        "colab_type": "text"
      },
      "source": [
        "##Question 3.3 LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc3fwCrYFCy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class ConcatenatedRNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "#                  bidirectional, dropout, pad_idx):\n",
        "        \n",
        "#         super().__init__()        \n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "#         self.rnn = nn.LSTM(embedding_dim, \n",
        "#                            hidden_dim, \n",
        "#                            num_layers=n_layers, \n",
        "#                            bidirectional=bidirectional, \n",
        "#                            dropout=dropout)\n",
        "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "#     def forward(self, text, parent, text_lengths):\n",
        "        \n",
        "#         text = torch.cat((parent, text), dim=0)\n",
        "#         embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "#         #pack sequence\n",
        "#         packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "#         packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "#         #unpack sequence\n",
        "#         output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "#         hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "#         #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "#         return torch.sigmoid(self.fc(hidden.squeeze(0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pdk_UJFC2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tick = time.time()\n",
        "# concat_rnn = ConcatenatedRNN(all_models_hyperparameters['vocabulary_size'],\n",
        "#           all_models_hyperparameters['embedding_dim'], \n",
        "#           two_utt_rnn_hyperparameters['hidden_size'],\n",
        "#           all_models_hyperparameters['output_dim'],\n",
        "#           two_utt_rnn_hyperparameters['number_of_layers'],\n",
        "#           two_utt_rnn_hyperparameters['bidirectional'],\n",
        "#           all_models_hyperparameters['dropout'],\n",
        "#           two_utt_rnn_hyperparameters['pad_idx'])\n",
        "\n",
        "# optimizer = optim.Adam(concat_rnn.parameters(), lr=two_utt_rnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# concat_rnn = train_model('concat-RNN-attempt-0-', concat_rnn, optimizer, criterion, variable_length=True)\n",
        "# print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnfprscFifv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_model_confusion_matrix(concat_rnn, variable_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhP41mjDh7z",
        "colab_type": "text"
      },
      "source": [
        "# Part 4.  Modeling sarcasm by separating context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vLkJ6QTqB4H",
        "colab_type": "text"
      },
      "source": [
        "##Utility cells for modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVol7AZVqEiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### hyperparameters\n",
        "# overall\n",
        "all_models_hyperparameters = {'embedding_dim': 100,\n",
        "                              'output_dim': 1,\n",
        "                              'dropout': 0.5,\n",
        "                              'vocabulary_size': len(TEXT.vocab),\n",
        "                              'number_of_epochs': 20,\n",
        "                              'batch_size': 50}\n",
        "\n",
        "# base lr\n",
        "# attempt 0: 0.001\n",
        "separate_lr_hyperparameters = {'learning_rate': 0.001}\n",
        "\n",
        "# base CNN\n",
        "# attempt 0: 200 x [1,2,3,4,5] x 0.0005 (bad)\n",
        "# attempt 1: 200 x [1,2,3,4,5] x 0.0001 (bad)\n",
        "# attempt 2: 50 x [3,4,5] x 0.0001 (good)\n",
        "# attempt 2.5: 80 x [3,4,5] x 0.00001 (too slow)\n",
        "# attempt 3: 80 x [3,4,5] x 0.0005 (good)\n",
        "# attempt 3: 80 x [3,4,5] x 0.0005 x 20 epochs (good)\n",
        "# jk all these are wrong\n",
        "\n",
        "# attempt 5: 20 x [2,3,4] x 0.0005 x 10 epochs (good)\n",
        "# attempt 6: \n",
        "# separate_cnn_hyperparameters = {'num_features': 20,\n",
        "#                             'filter_sizes': [2, 3, 4], #[2-6] didn't work\n",
        "#                             'learning_rate': 0.0005}\n",
        "\n",
        "# base RNN\n",
        "# attempt 0: 15 epochs, 256 hiddens, 2 layers, dropout = 0.2, lr = 0.0005\n",
        "# attempt 1: 15 epochs, 128 hiddens, 1 layers, dropout = 0.5, lr = 0.0001 (not quite as good)\n",
        "# attempt 2: 15 epochs, 256 hiddens, 1 layers, dropout = 0.2, lr = 0.001\n",
        "separate_rnn_hyperparameters = {'hidden_size': 256,\n",
        "                            'number_of_layers': 1,\n",
        "                            'bidirectional': True,\n",
        "                            'dropout': 0.2,\n",
        "                            'pad_idx': TEXT.vocab.stoi[TEXT.pad_token],\n",
        "                            'learning_rate': 0.0001}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw8GBSTHEXE7",
        "colab_type": "text"
      },
      "source": [
        "##Question 4.1 Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vhkt0V1ELIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class SeparateLogisticRegression(nn.Module):\n",
        "#     def __init__(self, embedding_dim, output_dim):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)  # we used GLove 100-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "#         self.fc = nn.Linear(2 * embedding_dim, output_dim)\n",
        "\n",
        "#     def forward(self, comment, parent_comment):\n",
        "#         def mean_embed(text):\n",
        "#             if len(text.size()) == 1:\n",
        "#                 text = torch.unsqueeze(text, dim=0)\n",
        "#             text = text.permute(1, 0)\n",
        "#             embedded = self.embed(text)\n",
        "#             embedded = embedded.permute(0, 2, 1)\n",
        "#             return torch.mean(embedded, dim=2)\n",
        "#         avg_embedded = torch.cat((mean_embed(comment), mean_embed(parent_comment)), dim=1)\n",
        "#         return torch.sigmoid(self.fc(avg_embedded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbTLAPbnm1_T",
        "colab_type": "text"
      },
      "source": [
        "##Question 4.2 CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sso5cRzFnCLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class SeparateCNN1d(nn.Module):\n",
        "#     def __init__(self, embedding_dim, num_features, filter_sizes, output_dim, dropout):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed = nn.Embedding(len(vocab), embedding_dim)  # we used GLove 100-dim\n",
        "#         self.embed.weight.data.copy_(vocab.vectors)\n",
        "\n",
        "#         self.conv_stack_1 = nn.ModuleList([\n",
        "#             nn.Conv1d(in_channels=embedding_dim,\n",
        "#                       out_channels=num_features,\n",
        "#                       kernel_size=fs)\n",
        "#             for fs in filter_sizes\n",
        "#         ])\n",
        "#         self.conv_stack_2 = nn.ModuleList([\n",
        "#             nn.Conv1d(in_channels=embedding_dim,\n",
        "#                       out_channels=num_features,\n",
        "#                       kernel_size=fs)\n",
        "#             for fs in filter_sizes\n",
        "#         ])\n",
        "\n",
        "#         self.fc = nn.Linear(2 * len(filter_sizes) * num_features, output_dim)\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     def forward(self, text, parent=None):\n",
        "#         def process_utterance(text, stack):\n",
        "#             text = text.permute(1, 0)\n",
        "#             embedded = self.embed(text)\n",
        "#             embedded = embedded.permute(0, 2, 1)\n",
        "#             conved = [F.relu(conv(embedded)) for conv in stack]\n",
        "#             pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "#             cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "#             return cat\n",
        "#         features_from_both = torch.cat((process_utterance(parent, self.conv_stack_1),\n",
        "#                                         process_utterance(text, self.conv_stack_2)),\n",
        "#                                        dim=1)\n",
        "#         return torch.sigmoid(self.fc(features_from_both))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Bs8rY3oQdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tick = time.time()\n",
        "# separate_cnn = SeparateCNN1d(all_models_hyperparameters['embedding_dim'],\n",
        "#                             separate_cnn_hyperparameters['num_features'],\n",
        "#                             separate_cnn_hyperparameters['filter_sizes'],\n",
        "#                             all_models_hyperparameters['output_dim'],\n",
        "#                             all_models_hyperparameters['dropout']).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(separate_cnn.parameters(), lr=separate_cnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# separate_cnn = train_model('separate-CNN-attempt-5-', separate_cnn, optimizer, criterion)\n",
        "# print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdIoTjVM1-S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_model_confusion_matrix(separate_cnn, variable_length=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvbk0rlgqIQ8",
        "colab_type": "text"
      },
      "source": [
        "##Question 4.3 RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzbWzPwIqHf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class SeparateRNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "#                  bidirectional, dropout, pad_idx):\n",
        "        \n",
        "#         super().__init__()        \n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "#         self.child_rnn = nn.LSTM(embedding_dim, \n",
        "#                            hidden_dim, \n",
        "#                            num_layers=n_layers, \n",
        "#                            bidirectional=bidirectional, \n",
        "#                            dropout=dropout)\n",
        "#         self.parent_rnn = nn.LSTM(embedding_dim, \n",
        "#                            hidden_dim, \n",
        "#                            num_layers=n_layers, \n",
        "#                            bidirectional=bidirectional, \n",
        "#                            dropout=dropout)\n",
        "#         self.fc = nn.Linear(hidden_dim * 4, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "#     def forward(self, text, parent, text_lengths):\n",
        "#         def process_utterance(text, rnn):\n",
        "#             embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "#             #pack sequence\n",
        "#             packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "#             packed_output, (hidden, cell) = rnn(packed_embedded)\n",
        "\n",
        "#             #unpack sequence\n",
        "#             output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "#             hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "#             return cat\n",
        "#         features_from_both = torch.cat((process_utterance(parent, self.parent_rnn),\n",
        "#                                         process_utterance(text, self.child_rnn)),\n",
        "#                                        dim=1)\n",
        "#         return torch.sigmoid(self.fc(features_from_both))\n",
        "\n",
        "# raise NotImplementedError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS5hqgxCUPHg",
        "colab_type": "code",
        "outputId": "61fe7220-5c36-4951-8e5f-ef166dc1a930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "two_utt_rnn_hyperparameters = {'hidden_size': 256,\n",
        "                            'number_of_layers': 1,\n",
        "                            'bidirectional': True,\n",
        "                            'dropout': 0.2,\n",
        "                            'pad_idx': TEXT.vocab.stoi[TEXT.pad_token],\n",
        "                            'learning_rate': 0.0001}\n",
        "\n",
        "all_models_hyperparameters = {'embedding_dim': 100,                             \n",
        "                              'output_dim': 1,\n",
        "                              'vocabulary_size': len(TEXT.vocab),\n",
        "                              'train_batch_size': 40,\n",
        "                              'test_batch_size': 40,\n",
        "                              'dropout': 0.5,}\n",
        "\n",
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "  def __init__(self, method, hidden_size):\n",
        "    super(Attn, self).__init__()\n",
        "    self.method = method\n",
        "    if self.method not in ['dot', 'general', 'concat']:\n",
        "      raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "    self.hidden_size = hidden_size\n",
        "    if self.method == 'general':\n",
        "      self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "    elif self.method == 'concat':\n",
        "      self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "      self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "  def dot_score(self, hidden, encoder_output):\n",
        "    return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "  def general_score(self, hidden, encoder_output):\n",
        "    energy = self.attn(encoder_output)\n",
        "    return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "  def concat_score(self, hidden, encoder_output):\n",
        "    energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "    return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs):\n",
        "    # Calculate the attention weights (energies) based on the given method\n",
        "    if self.method == 'general':\n",
        "      attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "    elif self.method == 'concat':\n",
        "      attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "    elif self.method == 'dot':\n",
        "      attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "    # Transpose max_length and batch_size dimensions\n",
        "    attn_energies = attn_energies.t()\n",
        "\n",
        "    # Return the softmax normalized probability scores (with added dimension)\n",
        "    return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "  \n",
        "  \n",
        "class RecModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "    super(RecModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "#     if not pretrained:\n",
        "#       self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "#     else:\n",
        "#       self.word_embeddings = nn.Embedding.from_pretrained(pretrained_weights)\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "    # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "    # with dimensionality hidden_dim.\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=(0 if n_layers == 1 else dropout))\n",
        "\n",
        "\n",
        "  def forward(self,  text, text_lengths):    \n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    \n",
        "    #pack sequence\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "    packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "\n",
        "    #unpack sequence\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "#     hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "#     cell = self.dropout(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim = 1))\n",
        "#     # Sort data by dereasing order of input lengths\n",
        "#     input_lengths, perm_index = input_lengths.sort(0, descending=True)\n",
        "#     body = body[perm_index]\n",
        "    \n",
        "#     # Compute the embeddings\n",
        "#     embedded = self.word_embeddings(body)\n",
        "    \n",
        "#     # Pack the padded sequence of inputs\n",
        "#     packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths,batch_first=True)\n",
        "    \n",
        "#     # Pass the input through the LSTM unit\n",
        "#     if hidden_input is not None:\n",
        "\n",
        "#       cell_input = torch.zeros(hidden_input.size()).to(device)\n",
        "\n",
        "#       output, (hidden, cell) = self.lstm(packed, (hidden_input,cell_input))\n",
        "#     else:\n",
        "#       output, (hidden, cell) = self.lstm(packed)\n",
        "    \n",
        "#     output, _ = nn.utils.rnn.pad_packed_sequence(output)\n",
        "    \n",
        "#     # Return the hidden vector from the LSTM\n",
        "    return output, hidden, cell\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "class AttnDecoder(nn.Module):\n",
        "  def __init__(self, attn_model, vocab_size, embedding_dim, hidden_size, output_size, pad_idx,  n_layers=1, dropout=0.1):\n",
        "    super(AttnDecoder, self).__init__()\n",
        "\n",
        "    # Keep for reference\n",
        "    self.attn_model = attn_model\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "    \n",
        "    \n",
        "    self.embedding_dropout = nn.Dropout(dropout)\n",
        "    self.gru = nn.GRU(embedding_dim, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "    self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "  def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "    # Note: we run this one step (word) at a time\n",
        "    # Get embedding of current input word\n",
        "#     embedded = self.embedding(input_step)\n",
        "    embedded = self.dropout(self.embedding(input_step))\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    \n",
        "    \n",
        "    # Forward through unidirectional GRU\n",
        "    embedded = torch.transpose(embedded, 0, 1)\n",
        "    rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "    # Calculate attention weights from the current GRU output\n",
        "    attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "    # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "    context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "    # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "    rnn_output = rnn_output.squeeze(0)\n",
        "    context = context.squeeze(1)\n",
        "    concat_input = torch.cat((rnn_output, context), 1)\n",
        "    concat_output = torch.tanh(self.concat(concat_input))\n",
        "    \n",
        "    output = self.out(concat_output)\n",
        "    \n",
        "    # Return output and final hidden state\n",
        "    return output, hidden\n",
        "  \n",
        "\n",
        "embedding_dim = 300\n",
        "hidden_dim = 300\n",
        "encoder = RecModel(all_models_hyperparameters['vocabulary_size'],\n",
        "          all_models_hyperparameters['embedding_dim'], \n",
        "          two_utt_rnn_hyperparameters['hidden_size'],\n",
        "          all_models_hyperparameters['output_dim'],\n",
        "          two_utt_rnn_hyperparameters['number_of_layers'],\n",
        "          two_utt_rnn_hyperparameters['bidirectional'],\n",
        "          all_models_hyperparameters['dropout'],\n",
        "          two_utt_rnn_hyperparameters['pad_idx']).to(device)\n",
        "\n",
        "attn_model = 'dot'\n",
        "hidden_size = 300\n",
        "\n",
        "# embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "decoder = AttnDecoder(attn_model, \n",
        "          all_models_hyperparameters['vocabulary_size'],\n",
        "          all_models_hyperparameters['embedding_dim'], \n",
        "          two_utt_rnn_hyperparameters['hidden_size'],\n",
        "          two_utt_rnn_hyperparameters['hidden_size'],\n",
        "          two_utt_rnn_hyperparameters['pad_idx'],\n",
        "          two_utt_rnn_hyperparameters['number_of_layers'],\n",
        "          all_models_hyperparameters['dropout']).to(device)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time, datetime\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(Classifier, self).__init__()\n",
        "    \n",
        "    self.fc1 = nn.Linear(hidden_dim, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 1)\n",
        "    \n",
        "    \n",
        "  def forward(self, data):\n",
        "    op = F.relu(self.fc1(data))\n",
        "    op = F.relu(self.fc2(op))\n",
        "    return self.fc3(op)\n",
        "  \n",
        "classifier = Classifier(two_utt_rnn_hyperparameters['hidden_size']).to(device)\n",
        "\n",
        "\n",
        "def train_attention(encoder, decoder, classifier, criterion, encoder_optimizer, decoder_optimizer, classifier_optimizer, num_epochs, logger):\n",
        "  # Training loop\n",
        "  batch_num=0\n",
        "  for epoch in range(0,num_epochs):\n",
        "    for i, ex in enumerate(train_iter):\n",
        "      batch_num=batch_num+1\n",
        "      lab, child, parent = ex.label.to(device), ex.comment.to(device), ex.parent_comment.to(device)\n",
        "      lengths_child = [list(c.size())[0] for c in child.permute(1, 0)]\n",
        "      lengths_parent = [list(c.size())[0] for c in parent.permute(1, 0)]\n",
        "      # Forward pass body through encoder\n",
        "      encoder_output, encoder_hidden, _ = encoder(parent, lengths_parent)\n",
        "      \n",
        "      # Initialize decoder hidden state to hidden state of encoder\n",
        "      decoder_hidden = encoder_hidden\n",
        "      \n",
        "      child = torch.transpose(child, 0, 1)\n",
        "      # Initialize decoder input to first word of child\n",
        "#       print(child)\n",
        "#       print(child.shape)\n",
        "      decoder_input = child[:,0].unsqueeze(1)\n",
        "      \n",
        "      # Forward batch of sequences through decoder\n",
        "      max_child_length = child.size(1)\n",
        "#       print(max_child_length)\n",
        "      for i in range(1,max_child_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "        \n",
        "        decoder_input = child[:,i].unsqueeze(1)\n",
        "\n",
        "      \n",
        "      output = classifier(decoder_hidden)\n",
        "      output = output.view(output.size(1),-1)\n",
        "      output = output.squeeze(1)\n",
        "      loss = criterion(output.float(), lab.float())\n",
        "      \n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "      classifier_optimizer.zero_grad()\n",
        "      \n",
        "      loss.backward()\n",
        "      \n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "      classifier_optimizer.step()\n",
        "\n",
        "      #Compute accuracy\n",
        "      predicted = torch.round(torch.sigmoid(output.data))\n",
        "      total = lab.size(0)\n",
        "      correct = (predicted.float() == lab.to(device).float()).sum().item()\n",
        "      accuracy = correct / total\n",
        "      info = { 'loss': loss, 'accuracy': accuracy }\n",
        "      print(info)\n",
        "      if batch_num%500==0:\n",
        "        test_total = 0\n",
        "        test_correct = 0\n",
        "        test_batch_num=0\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            for i, ex in enumerate(test_iter):\n",
        "              test_batch_num=test_batch_num+1\n",
        "              if test_batch_num>50:\n",
        "                break\n",
        "              lab, child, parent = ex.label.to(device), ex.comment.to(device), ex.parent_comment.to(device)\n",
        "              lengths_child = [list(c.size())[0] for c in child.permute(1, 0)]\n",
        "              lengths_parent = [list(c.size())[0] for c in parent.permute(1, 0)]\n",
        "              # Forward pass body through encoder\n",
        "              encoder_output, encoder_hidden, _ = encoder(parent, lengths_parent)\n",
        "\n",
        "              # Initialize decoder hidden state to hidden state of encoder\n",
        "              decoder_hidden = encoder_hidden\n",
        "\n",
        "              child = torch.transpose(child, 0, 1)\n",
        "              decoder_input = child[:,0].unsqueeze(1)\n",
        "\n",
        "              # Forward batch of sequences through decoder\n",
        "              max_child_length = child.size(1)\n",
        "        #       print(max_child_length)\n",
        "              for i in range(1,max_child_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "\n",
        "                decoder_input = child[:,i].unsqueeze(1)\n",
        "\n",
        "\n",
        "              output = classifier(decoder_hidden)\n",
        "              output = output.view(output.size(1),-1)\n",
        "              output = output.squeeze(1)\n",
        "              #Compute accuracy\n",
        "              predicted = torch.round(torch.sigmoid(output.data))\n",
        "              test_total = test_total+lab.size(0)\n",
        "              test_correct = test_correct+(predicted.float() == lab.to(device).float()).sum().item()\n",
        "              test_accuracy = test_correct / test_total\n",
        "              info['test_accuracy'] = test_accuracy   \n",
        "              torch.save(encoder.state_dict(), \"/content/gdrive/My Drive/hw-3-models/\" + 'encoder_attention' + \"-\" + str(batch_num))\n",
        "              torch.save(decoder.state_dict(), \"/content/gdrive/My Drive/hw-3-models/\" + 'decoder_attention' + \"-\" + str(batch_num))\n",
        "              torch.save(classifier.state_dict(), \"/content/gdrive/My Drive/hw-3-models/\" + 'encoder_decoder_classifier_attention' + \"-\" + str(batch_num))\n",
        "\n",
        "      for tag, value in info.items():\n",
        "          logger.scalar_summary(tag, value, batch_num + 1)     \n",
        "  return encoder, decoder, classifier\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPn_tjhcl44",
        "colab_type": "code",
        "outputId": "0c2aa077-4940-4a87-bc29-0af82fc59a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63991
        }
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "learning_rate = 0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 0.01) \n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 0.01) \n",
        "classifier_optimizer = optim.Adam(classifier.parameters(), lr = 0.003) \n",
        "\n",
        "# TRAINING LOOP\n",
        "now = time.mktime(datetime.datetime.now().timetuple())\n",
        "logger = Logger(f'./logs/run_{now}/')\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "encoder, decoder, classifier=train_attention(encoder, decoder, classifier, criterion, encoder_optimizer, decoder_optimizer, classifier_optimizer, num_epochs, logger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': tensor(0.7034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7223, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7560, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6984, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.75}\n",
            "{'loss': tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.9607, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.25}\n",
            "{'loss': tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.225}\n",
            "{'loss': tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.3}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.275}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7313, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7036, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6752, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6738, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6738, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6721, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7213, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6561, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7147, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6689, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7036, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6745, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6699, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6461, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7231, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6579, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6705, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7139, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7180, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6728, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6664, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6721, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6765, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6738, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6611, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6386, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6371, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6480, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7240, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6445, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6544, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6699, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6573, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6469, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6526, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6527, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6682, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6543, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7025, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.5962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6587, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7158, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6391, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6709, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7206, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6453, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6440, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.775}\n",
            "{'loss': tensor(0.6757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6735, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6546, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7050, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6499, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.75}\n",
            "{'loss': tensor(0.7598, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6553, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7210, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6219, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.775}\n",
            "{'loss': tensor(0.6618, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.5893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.5961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7531, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6629, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.7075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7173, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7384, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.3}\n",
            "{'loss': tensor(0.7268, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6614, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6702, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6789, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6706, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6719, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6765, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6761, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6649, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7414, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6499, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6703, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6589, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6618, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6632, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6702, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6696, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6699, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6531, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.75}\n",
            "{'loss': tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7195, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7149, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6668, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6690, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7017, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6736, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.3}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.8}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6602, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6862, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7377, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6459, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6607, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7203, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.3}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7327, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6524, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6781, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7407, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7145, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7174, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6625, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6634, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7246, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6646, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6560, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6617, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7279, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7267, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6693, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7326, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6493, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6316, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7293, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7176, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6686, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6772, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6609, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6605, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6609, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6596, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6429, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6823, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6604, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6573, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6397, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6549, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6629, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6548, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6602, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6573, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6578, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6844, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7621, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.7007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6584, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6807, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6693, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6866, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6811, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6685, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6598, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7061, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6692, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6617, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6572, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6790, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7307, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7308, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7514, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7298, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6835, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6689, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.25}\n",
            "{'loss': tensor(0.7021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7282, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6713, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6557, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7107, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6520, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6651, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6737, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6474, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7505, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6821, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7220, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6632, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6632, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6417, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6750, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6794, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6433, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6709, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6577, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6638, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7255, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7125, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6504, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6579, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7109, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6660, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6746, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6633, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6547, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6621, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.7216, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6650, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7555, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7127, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6492, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6681, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6832, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7150, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6737, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6772, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6772, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6650, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6671, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6860, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6589, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.75}\n",
            "{'loss': tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6646, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6451, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6182, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7387, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7190, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6476, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6440, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.7273, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6721, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7141, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7297, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.35}\n",
            "{'loss': tensor(0.7365, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.325}\n",
            "{'loss': tensor(0.6778, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6728, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7132, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7324, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6618, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6753, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6565, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6663, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6720, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6623, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6602, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6632, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6639, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6644, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6700, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6640, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6189, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6490, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6802, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7485, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6464, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6606, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6661, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7369, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6550, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.7}\n",
            "{'loss': tensor(0.6759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6757, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6654, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6693, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.7051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6726, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6798, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6454, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6690, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6604, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6505, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6417, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.725}\n",
            "{'loss': tensor(0.6814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6717, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7161, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6622, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6636, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.7092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6562, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7235, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.7514, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6672, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7028, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.7014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6767, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.675}\n",
            "{'loss': tensor(0.6893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6736, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6810, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7058, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6842, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6734, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6622, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.7274, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6680, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6582, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6806, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6822, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6598, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.6751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6921, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.7153, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6721, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7017, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(0.7164, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.7013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6600, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.7330, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.375}\n",
            "{'loss': tensor(0.6908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.575}\n",
            "{'loss': tensor(0.6864, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6815, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.55}\n",
            "{'loss': tensor(0.6849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.7096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.6796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.625}\n",
            "{'loss': tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.45}\n",
            "{'loss': tensor(0.7093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.4}\n",
            "{'loss': tensor(0.6669, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.65}\n",
            "{'loss': tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.525}\n",
            "{'loss': tensor(0.6881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.475}\n",
            "{'loss': tensor(0.6759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.5}\n",
            "{'loss': tensor(0.6599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.6}\n",
            "{'loss': tensor(0.6945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.425}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n",
            "{'loss': tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'accuracy': 0.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-11ecd538fee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-5308f3361e2b>\u001b[0m in \u001b[0;36mtrain_attention\u001b[0;34m(encoder, decoder, classifier, criterion, encoder_optimizer, decoder_optimizer, classifier_optimizer, num_epochs, logger)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;31m#       print(max_child_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_child_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-5308f3361e2b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_step, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m#     embedded = self.embedding(input_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    828\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    829\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytPEKoShq34C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tick = time.time()\n",
        "# separate_rnn = SeparateRNN(all_models_hyperparameters['vocabulary_size'],\n",
        "#           all_models_hyperparameters['embedding_dim'], \n",
        "#           two_utt_rnn_hyperparameters['hidden_size'],\n",
        "#           all_models_hyperparameters['output_dim'],\n",
        "#           two_utt_rnn_hyperparameters['number_of_layers'],\n",
        "#           two_utt_rnn_hyperparameters['bidirectional'],\n",
        "#           all_models_hyperparameters['dropout'],\n",
        "#           two_utt_rnn_hyperparameters['pad_idx'])\n",
        "\n",
        "# optimizer = optim.Adam(separate_rnn.parameters(), lr=two_utt_rnn_hyperparameters['learning_rate'])\n",
        "\n",
        "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "# concat_rnn = train_model('separate-RNN-attempt-0-', separate_rnn, optimizer, criterion, variable_length=True)\n",
        "# print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBgAW61q4M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}